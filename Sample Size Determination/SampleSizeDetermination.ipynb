{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Sample Size Determination<h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first steps to designing a successful experiment is determining the number of samples that you need in order to have confidence in the results. We don’t want to go through the trouble of running an A/B test or administering a survey only to discover that we don’t have enough information to make a good decision.\n",
    "\n",
    "In this lesson we’ll cover two common types of experiment and their methods of sample size determination:\n",
    "* A/B Tests\n",
    "* Surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An A/B Test is a scientific method of choosing between two options (Option A and Option B). Some examples of A/B tests would include:\n",
    "\n",
    "* What number of sale items on a website makes customers most likely to purchase something: 25 or 50?\n",
    "* What color button are customers more likely to click on: blue or green?\n",
    "\n",
    "In order to determine the sample size necessary for an A/B test, a sample size calculator requires three numbers:\n",
    "\n",
    "* The *Baseline conversion rate*\n",
    "* The *Minimum detectable effect*\n",
    "* The *Statistical significance*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B tests compare an option that we’re currently using to a new option that we suspect might be better. In order to compare the two options, we need a metric. Generally, our metric will be the percent of users who take a certain action after interacting with one of our options. For instance:\n",
    "\n",
    "* The percent of customers who **buy a t-shirt** after visiting one of two versions of a website.\n",
    "* The percent of users who **click** one of two versions of an ad.\n",
    "* The percent of readers who **open an email** with one of two subject lines.\n",
    "\n",
    "In order to calculate the sample size for our A/B test, we need to know whether we expect our metric to be low or high. It will take more samples to be able to spot a difference when our metric is extremely low or extremely high. Our initial estimate of our metric is called a **baseline**.\n",
    "\n",
    "We can usually calculate a baseline by looking at historical data for the option that we’re currently using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Viral Villanelle is an American internet media company specializing in social news and digital media. \n",
    "Here we looked at how many people visited the website within a ten minute window and how many engaged\n",
    "in our top headline this week: Seventeen Gross Facts About Your Elbows, Number Three Will Astound You. \n",
    "We’ve calculated the quantity of each, saving the values in number_of_site_visitors and \n",
    "number_of_converted_visitors, but would like to know what our conversion rate is\n",
    "\"\"\"\n",
    "\n",
    "# Find the size of both of these lists\n",
    "number_of_site_visitors = 2000.0\n",
    "number_of_converted_visitors = 1300.0\n",
    "\n",
    "# Calculate the conversion rate in terms of the above two variables here\n",
    "conversion_rate = number_of_converted_visitors/number_of_site_visitors\n",
    "print(conversion_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining Lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re running an A/B Test in order to know if Option B is better than Option A but if Option B were only a tiny percent better, would we really care? In order to detect precise differences, we need a very large sample size. In order to choose a sample size, we need to know the smallest difference that we actually care to measure. This \"smallest difference\" is called **lift**.\n",
    "\n",
    "Lift is generally expressed as a percent of the baseline conversion rate. Suppose that 6% of our customers currently buy socks on our website Sock Hops (that’s our baseline conversion rate). We think that a new website layout would increase this. Changing a website layout is hard, so we only think that it’s worth doing if at least 8% of our customers would buy socks on Sock Hops with the new layout. That means that we want to increase our conversions by 2%. To calculate lift:\n",
    "```python\n",
    "100 * (new - old) / old\n",
    "100 * (8 - 6) / 6\n",
    "33%\n",
    "```    \n",
    "Sock Hops’ desired lift is 33%. (this would be the minimum detectable effect, i.e the lift of 2% as the proportion of the baseline 6%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't Interfere With Your Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brian the Product Manager has been running an A/B Test for a redesign of Viral Villanelle’s landing page. Brian used the principles in the Sample Size Determination course on Codecademy to calculate a sample size. He needs 1,100 users to view each variant of the landing page in order to be able to detect his desired lift. When he reaches a total of 2,200 visits to both variants, he runs a Chi-Square test. The new website design performs slightly better, but the results are not statistically significant. Brian decides to run the test for another week to see if he can get to significance. He really wants to launch the redesigned website and he needs statistical validation to show to his boss.\n",
    "\n",
    "Brian has made a big mistake! By choosing to extend the A/B test past the sample size he needs, he introduces personal bias to the results of the test.\n",
    "\n",
    "If the results had already been significant, he wouldn’t have run the test any longer. If he continues this pattern of preferentially extending the test when he wants a different answer, he will be more likely to get the results he wants, regardless if these desired results reflect reality.\n",
    "\n",
    "It’s sad, but Brian will need to accept that the redesigned website isn’t significantly better than the original website.\n",
    "\n",
    "Here are two important rules for making sure that A/B tests remain unbiased:\n",
    "\n",
    "* Don't continue to run the test beyond the predetermined sample size, until \"significant\" results are found.\n",
    "* Don't stop a test before reaching the predetermined sample size, just because your results reach significance early (unless there are ethical reasons that require you to stop, like a prescription drug trial).\n",
    "\n",
    "Test data is sensitive to changes in sample size, which is why it is important to calculate beforehand.\n",
    "\n",
    "Inspect the graph in the workspace. It shows an A/B Test where the baseline was 5%, and we want to see a lift of 50% (i.e., we want our second option to have at least a 7.5% conversion rate). A sample size calculator tells us that we need 210 samples. The chart shows the cumulative conversion rate after each new sample. When we reach our desired 210 samples, our cumulative conversion rate is slightly higher than 5%, but the difference is not significantly different (indicated by red). By extending the experiment to 320 samples, the difference becomes significantly different (indicated by green). We might conclude that our results are significant if we stopped the experiment at this point. However, we can see this is a temporary fluctuation. After this brief moment of “significance” the conversion rate decreases and our results become insignificant again. By arbitrarily extending the study until it reaches significance, we fool ourselves!\n",
    "\n",
    "Try this: Flip a coin five times. Which side came up more frequently? Perhaps you now suspect that the coin is biased. Keep flipping the coin until that side shows up even more frequently. By changing your sample size in the middle of an experiment, you can easily convince yourself that a fair coin is biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graph.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting a Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viral Villanelle’s social media presence drives visits to its website. Product Manager Brian wants to test a new ad. Using a sample size calculator, he finds that he will need a sample size of 1,100. Viral Villanelle’s current advertisement is shown to 500 users per day. What’s the best way for Brian to get his desired sample size?\n",
    "\n",
    "t’s important to remember that Brian will need to show both the old and the new ad to 1,100 users *each.* If Brian wants to complete this test as quickly as possible, he could randomly divide users into two groups: half of users would see the old ad and half would see the new ad. It would take a little more than 4 days for 2,200 users to see one of the two ads.\n",
    "\n",
    "What if Brian doesn’t want to divide Viral Villanelle’s audience evenly? If Brian is running many different types of A/B tests, he might not want to expose users to a barrage of different tests. Maybe only 10% of users should be shown the new ad, in case it performs terribly. By doing this, he would only be getting 50 users per day towards the 1,100 users that need to see the new ad. In this case, he would need to wait for 22 days (1100 / 50 = 22) in order to get his results, even though he would have gotten the 1,100 views for the old ad 3 days into the experiment.\n",
    "\n",
    "For his final analysis, Brian should use all of the data from the 22 days. The Chi-Square test will correctly take into account that there is more data from the original ad than from the new ad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surveys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s imagine that we own a juice bar called BeetsMe in the small town of Vancucumber. We want to know what our customers’ favorite vegetable is so that we know what to base our next juice recipe around. How many people do we need to survey to be confident in our results?\n",
    "\n",
    "It is easy to find a sample size calculator online, but it is difficult to determine what parameters to input. Generally, sample size calculators use 4 parameters:\n",
    "\n",
    "* Margin of error\n",
    "* Confidence level\n",
    "* Population size\n",
    "* Expected proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Margin of Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean to have “enough” people for a survey? Generally, we are making sure that our results are within a **margin of error** of the correct answer.\n",
    "\n",
    "The margin of error is the furthest we expect the true value to be from what we measure in our survey. For example, let’s say we choose a margin of error of 4%. If we get results showing 40% of people love beets the most, we can be confident that the true proportion in the population lies somewhere between 36% and 44%. Thus, the smaller we make the margin of error, the more certainty we have in the results. The larger we make the margin of error, more uncertain we are that they represent the views of the total population.\n",
    "\n",
    "In order to make our margin of error smaller, we will need a larger sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sample should accurately represent the population as a whole. So, when we are dealing with a larger population, we should probably be sampling more people.\n",
    "\n",
    "It is sometimes tricky to determine what the effective population size is. For example, suppose there are 200 people who currently visit BeetsMe regularly. Is 200 the population size for our vegetable survey?\n",
    "\n",
    "If BeetsMe wants to appeal to the tourists that frequently visit Vancucumber, or if they ever want to launch an online store to ship healthy treats all over the world, the real population size is closer to 8 billion (or infinity, really, if we think about the number of humans who could eventually exist and have vegetable preferences). So, for experiments like this, we use the highest population size we can. Normally, 100,000 will suffice, as changes become negligible beyond that.\n",
    "\n",
    "Often, for decisions that require extrapolation to an unknown customer base, it is important to understand the preferences of a typical person out in the world, whether or not they are part of your customer base right now. Generally, we use this larger population size of 100,000 or greater instead of focusing on the amount of current customers.\n",
    "\n",
    "However, if the small town of Vancucumber is holding an election for a new mayor, and we want to project the results of the election, then the 1700 citizens would be the only important people. In this case, 1700 is the population size we would use in a sample size calculator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likely Sample Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, before we conduct a survey, we have a guess of what we expect the results to be. This guess could be based upon the results from a previous survey, or perhaps the results of a small pilot study before the real study.\n",
    "\n",
    "As the expected proportion of people with the desired trait decreases, we can survey fewer people. For example, if we are projecting election results and Candidate C has 1% of the voter base, taking a small sample of only 5 people might be fine, because it is very likely that no one we have chosen is voting for Candidate C. This is close enough to the true proportion.\n",
    "\n",
    "As the expected proportion increases, it is rarer that we hit that proportion accurately with the random sample we choose.\n",
    "\n",
    "If we do not have historical data, we normally use 50%, which gives the most conservative (i.e., largest required) sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to choose a confidence level. The **confidence level** is the probability that the margin of error contains the true proportion. For example, if we choose a confidence level of 99%, we can expect that after multiple repetitions of the survey, the true value will lie within our specified range 99% of the time. As we increase the confidence level, we must have a larger sample size.\n",
    "\n",
    "We normally use a confidence level of 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it together. Sample size of a survey: Example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are now conducting the survey to see if beets are the best vegetable to choose as a base for our new juice.\n",
    "Our product manager tells us that we want to be within 4% of the correct answer, with a 95% confidence level.\n",
    "\n",
    "The town of Vancucumber is made up of 1700 people. \n",
    "We estimate that 40% of people think that the beet is the best vegetable.\n",
    "\"\"\"\n",
    "\n",
    "margin_of_error = 4\n",
    "confidence_level = 95\n",
    "likely_proportion = 40\n",
    "population_size = 100000\n",
    "\n",
    "\"\"\"\n",
    "Enter the values you decided on for margin of error, confidence level, population size, \n",
    "and likely population proportion into the sample size calculator. What sample size do we need?\n",
    "\"\"\"\n",
    "\n",
    "sample_size = 573 #Calculator result\n",
    "\n",
    "\"\"\"\n",
    "You know that you get 600 customers into BeetsMe per week. \n",
    "We estimate that 20% (or 120) of them will answer the written survey that we hand them with their receipt. \n",
    "How many weeks will it take to get the appropriate number of survey responses?\n",
    "\"\"\"\n",
    "# 573/120 = 4.775  ~ 5\n",
    "weeks_of_survey = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differing Survey Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are going to survey a group of high school students to see what programming language they want to learn. In the survey, we give the students two choices: JavaScript or Python. This seems like a problem where we would use a Sample Size Survey Calculator.\n",
    "\n",
    "But what if we don’t care about getting a specific margin of error? What if instead, we want to make a comparison: Are girls more likely to want to learn Python than boys are?\n",
    "\n",
    "This survey is more similar to an A/B Test. Our *baseline* is the approximate percent of the population who want to learn Python, and our *lift* is the minimum difference between boys and girls that we want to be able to detect.\n",
    "\n",
    "Whenever we want to make comparisons between subpopulations in our survey, we must use the A/B Test Calculator in order to get our desired survey size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A local high school is having a battle of the bands because they can’t decide who should play the Junior/Senior dance.\n",
    "All the big names are going to give it a shot: The Secretariats, Frank & Stein’s Monsters, Bad Words, even Sour Candy. \n",
    "We suspect that Sour Candy is more popular with seniors than with juniors. \n",
    "In previous years, about 35% of students preferred Sour Candy. \n",
    "We’re worried about a difference of more than 14 percentage points (40% difference),\n",
    "and only need to be 85% sure of the significance. \n",
    "How many students should we invite to the battle of the bands in order to test our hypothesis? \n",
    "Save your answer to band_battle_sample_size.\n",
    "\"\"\"\n",
    "\n",
    "baseline_conversion_rate = 0.35\n",
    "statistical_significance = 0.85\n",
    "minimum_detectable_effect = 0.40\n",
    "\n",
    "\n",
    "calculator_result_sample_size = 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
